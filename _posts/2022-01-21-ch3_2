## 심층 전방향 신경망

### 모델 아키텍쳐

## Raw Data전처리


```python
import pandas as pd
import sys, os
sys.path.append(os.pardir)
from common.data_preprocess import preprocess, feature_engineer

df = pd.read_csv('new-york-city-taxi-fare-prediction/NYC_taxi.csv',parse_dates=['pickup_datetime'], nrows=500000)

print(df.describe())
print('')
print('')

# 전처리 모듈 사용
# preprocess(df) : 
# feature_engineer(df) : 

df = preprocess(df)
df = feature_engineer(df)

df.head()
```

             fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \
    count  500000.000000     500000.000000    500000.000000      499995.000000   
    mean       11.358361        -72.519958        39.920276         -72.522435   
    std         9.916617         11.856831         8.073475          11.797362   
    min       -44.900000      -2986.242495     -3116.285383       -3383.296608   
    25%         6.000000        -73.992047        40.734917         -73.991382   
    50%         8.500000        -73.981785        40.752670         -73.980126   
    75%        12.500000        -73.967117        40.767076         -73.963572   
    max       500.000000       2140.601160      1703.092772          40.851027   
    
           dropoff_latitude  passenger_count  
    count     499995.000000    500000.000000  
    mean          39.916526         1.683428  
    std            7.391002         1.307395  
    min        -2559.748913         0.000000  
    25%           40.734057         1.000000  
    50%           40.753152         1.000000  
    75%           40.768135         2.000000  
    max          404.616667         6.000000  
    
    
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>fare_amount</th>
      <th>pickup_longitude</th>
      <th>pickup_latitude</th>
      <th>dropoff_longitude</th>
      <th>dropoff_latitude</th>
      <th>passenger_count</th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>day_of_week</th>
      <th>hour</th>
      <th>travel_distance</th>
      <th>pickup_dist_JFK_Airport</th>
      <th>dropoff_dist_JFK_Airport</th>
      <th>pickup_dist_Laguardia_Airport</th>
      <th>dropoff_dist_Laguardia_Airport</th>
      <th>pickup_dist_Newark_Airport</th>
      <th>dropoff_dist_Newark_Airport</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>4.5</td>
      <td>-73.844311</td>
      <td>40.721319</td>
      <td>-73.841610</td>
      <td>40.712278</td>
      <td>1</td>
      <td>2009</td>
      <td>6</td>
      <td>15</td>
      <td>0</td>
      <td>17</td>
      <td>0.009436</td>
      <td>0.101340</td>
      <td>0.092710</td>
      <td>0.055043</td>
      <td>0.064326</td>
      <td>0.337147</td>
      <td>0.339123</td>
    </tr>
    <tr>
      <th>1</th>
      <td>16.9</td>
      <td>-74.016048</td>
      <td>40.711303</td>
      <td>-73.979268</td>
      <td>40.782004</td>
      <td>1</td>
      <td>2010</td>
      <td>1</td>
      <td>5</td>
      <td>1</td>
      <td>16</td>
      <td>0.079696</td>
      <td>0.245731</td>
      <td>0.242961</td>
      <td>0.157402</td>
      <td>0.109925</td>
      <td>0.165330</td>
      <td>0.220812</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5.7</td>
      <td>-73.982738</td>
      <td>40.761270</td>
      <td>-73.991242</td>
      <td>40.750562</td>
      <td>2</td>
      <td>2011</td>
      <td>8</td>
      <td>18</td>
      <td>3</td>
      <td>0</td>
      <td>0.013674</td>
      <td>0.234714</td>
      <td>0.237050</td>
      <td>0.113076</td>
      <td>0.122790</td>
      <td>0.209742</td>
      <td>0.198236</td>
    </tr>
    <tr>
      <th>3</th>
      <td>7.7</td>
      <td>-73.987130</td>
      <td>40.733143</td>
      <td>-73.991567</td>
      <td>40.758092</td>
      <td>1</td>
      <td>2012</td>
      <td>4</td>
      <td>21</td>
      <td>5</td>
      <td>4</td>
      <td>0.025340</td>
      <td>0.225895</td>
      <td>0.240846</td>
      <td>0.122792</td>
      <td>0.122149</td>
      <td>0.197636</td>
      <td>0.200358</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5.3</td>
      <td>-73.968095</td>
      <td>40.768008</td>
      <td>-73.956655</td>
      <td>40.783762</td>
      <td>1</td>
      <td>2010</td>
      <td>3</td>
      <td>9</td>
      <td>1</td>
      <td>7</td>
      <td>0.019470</td>
      <td>0.225847</td>
      <td>0.225878</td>
      <td>0.098115</td>
      <td>0.087741</td>
      <td>0.225807</td>
      <td>0.242228</td>
    </tr>
  </tbody>
</table>
</div>




```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import scale

df_prescaled = df.copy()

df_scaled= df_prescaled.drop(['fare_amount'],axis=1)

df_scaled = scale(df_scaled)


cols=df.columns.tolist()
cols.remove('fare_amount')
df_scaled = pd.DataFrame(df_scaled, columns=cols, index=df.index)
df_scaled = pd.concat([df_scaled, df['fare_amount']], axis=1)
df = df_scaled.copy()

df.describe()
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>pickup_longitude</th>
      <th>pickup_latitude</th>
      <th>dropoff_longitude</th>
      <th>dropoff_latitude</th>
      <th>passenger_count</th>
      <th>year</th>
      <th>month</th>
      <th>day</th>
      <th>day_of_week</th>
      <th>hour</th>
      <th>travel_distance</th>
      <th>pickup_dist_JFK_Airport</th>
      <th>dropoff_dist_JFK_Airport</th>
      <th>pickup_dist_Laguardia_Airport</th>
      <th>dropoff_dist_Laguardia_Airport</th>
      <th>pickup_dist_Newark_Airport</th>
      <th>dropoff_dist_Newark_Airport</th>
      <th>fare_amount</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3.916930</td>
      <td>-1.128230</td>
      <td>4.151170</td>
      <td>-1.365544</td>
      <td>-0.526894</td>
      <td>-1.469613</td>
      <td>-0.078206</td>
      <td>-0.078224</td>
      <td>-1.560814</td>
      <td>0.535440</td>
      <td>-0.646419</td>
      <td>-3.957865</td>
      <td>-4.628104</td>
      <td>-2.321222</td>
      <td>-1.901182</td>
      <td>3.494487</td>
      <td>3.621456</td>
      <td>4.5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.203467</td>
      <td>-1.510232</td>
      <td>-0.146055</td>
      <td>1.083481</td>
      <td>-0.526894</td>
      <td>-0.932847</td>
      <td>-1.531643</td>
      <td>-1.230177</td>
      <td>-1.047528</td>
      <td>0.381406</td>
      <td>1.292346</td>
      <td>0.651855</td>
      <td>0.632001</td>
      <td>1.791579</td>
      <td>-0.076302</td>
      <td>-1.403330</td>
      <td>0.144378</td>
      <td>16.9</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-0.210318</td>
      <td>0.395471</td>
      <td>-0.519843</td>
      <td>-0.020874</td>
      <td>0.239920</td>
      <td>-0.396082</td>
      <td>0.503169</td>
      <td>0.267361</td>
      <td>-0.020956</td>
      <td>-2.083148</td>
      <td>-0.529470</td>
      <td>0.300109</td>
      <td>0.425082</td>
      <td>0.010531</td>
      <td>0.438549</td>
      <td>-0.137324</td>
      <td>-0.519141</td>
      <td>5.7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.341267</td>
      <td>-0.677272</td>
      <td>-0.529989</td>
      <td>0.243606</td>
      <td>-0.526894</td>
      <td>0.140684</td>
      <td>-0.659581</td>
      <td>0.612947</td>
      <td>1.005616</td>
      <td>-1.467010</td>
      <td>-0.207543</td>
      <td>0.018576</td>
      <td>0.557969</td>
      <td>0.400943</td>
      <td>0.412877</td>
      <td>-0.482406</td>
      <td>-0.456750</td>
      <td>7.7</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.226268</td>
      <td>0.652453</td>
      <td>0.559848</td>
      <td>1.145228</td>
      <td>-0.526894</td>
      <td>-0.932847</td>
      <td>-0.950268</td>
      <td>-0.769396</td>
      <td>-1.047528</td>
      <td>-1.004906</td>
      <td>-0.369548</td>
      <td>0.017031</td>
      <td>0.033961</td>
      <td>-0.590578</td>
      <td>-0.964116</td>
      <td>0.320637</td>
      <td>0.773768</td>
      <td>5.3</td>
    </tr>
  </tbody>
</table>
</div>



## Keras 모델 만들기
### 학습 데이터셋 구성하기


```python
#------------------------학습 데이터셋 정의---------------------------------------------------------------
import numpy as np
from sklearn.model_selection import train_test_split
X = df.loc[:,df.columns !='fare_amount']
y = df.loc[:, 'fare_amount']

XX = np.array(X)
yy = np.array(y)
print(XX.shape)
print(yy.shape)
print(XX.shape[1])


X_train, X_test, y_train, y_test = train_test_split(X,y, test_size =0.2)

#------------------------학습 DNN----------------------------------------------------------------
from keras.models import Sequential
from keras.layers import Dense


model = Sequential()
model.add(Dense(128,activation='relu', input_dim= X_train.shape[1]))
model.add(Dense(64,activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(8,activation='relu'))
model.add(Dense(1))

model.summary() # DNN 모델구조 확인

model.compile(loss='mse', optimizer='adam', metrics=['mse'] )


#모델 학습
model.fit(X_train, y_train, epochs=1)

```

    (483427, 17)
    (483427,)
    17
    Model: "sequential_9"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    dense_47 (Dense)             (None, 128)               2304      
    _________________________________________________________________
    dense_48 (Dense)             (None, 64)                8256      
    _________________________________________________________________
    dense_49 (Dense)             (None, 32)                2080      
    _________________________________________________________________
    dense_50 (Dense)             (None, 8)                 264       
    _________________________________________________________________
    dense_51 (Dense)             (None, 1)                 9         
    =================================================================
    Total params: 12,913
    Trainable params: 12,913
    Non-trainable params: 0
    _________________________________________________________________
    12086/12086 [==============================] - 66s 5ms/step - loss: 17.9257 - mse: 17.9257
    




    <keras.callbacks.History at 0x1c399d35320>



## 결과분석
### 요금예측


```python
def predict_random(df_prescaled, X_test, model):
    sample = X_test.sample(n=1, random_state=np.random.randint(low=0, high=10000))
    idx = sample.index[0]
    
    actual_fare = df_prescaled.loc[idx, 'fare_amount']
    day_names = ['Monday','Tuesday','Wednesday','Thrusday','Friday','Saturday', 'Sunday']
    day_of_week = day_names[df_prescaled.loc[idx,'day_of_week']]
    hour = df_prescaled.loc[idx,'hour']
    predicted_fare = model.predict(sample)[0][0]
    rmse=np.sqrt(np.square(predicted_fare-actual_fare))
    print('Trip Details:{},{}:00hrs'.format(day_of_week,hour))
    print('Actual fare:${:0.2f}'.format(actual_fare))
    print('Predicted fare:${:0.2f}'.format(predicted_fare))
    print('RMSE: ${:0.2f}'.format(rmse))
    

predict_random(df_prescaled, X_test, model)

```

    Trip Details:Saturday,13:00hrs
    Actual fare:$4.90
    Predicted fare:$6.56
    RMSE: $1.66
    


```python

```


```python

```


```python

```
